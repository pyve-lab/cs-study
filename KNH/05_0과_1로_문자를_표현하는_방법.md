# 5강 0과 1로 문자를 표현하는 방법

---

## 1. 컴퓨터는 문자를 그대로 이해하지 못한다

컴퓨터는 문자 자체를 이해하지 못한다.

컴퓨터가 이해할 수 있는 것은 **0과 1**뿐이다.

따라서 문자는 다음 과정을 거쳐 처리된다.

- 문자를 **숫자로 변환**
- 숫자를 **0과 1로 표현**

즉,

> 문자 → 숫자 → 0과 1의 과정을 거쳐 저장되고 처리된다.
> 

---

## 2. 문자 인코딩이란?

문자 인코딩(Character Encoding)이란 **문자를 숫자로 바꾸는 규칙**이다.

- 같은 문자라도
- 어떤 인코딩 규칙을 사용하느냐에 따라
- 서로 다른 숫자로 표현될 수 있다

---

## 3. ASCII 코드

### 3.1 ASCII란?

ASCII는 가장 기본적인 문자 인코딩 방식이다.

- 영문 알파벳
- 숫자
- 일부 특수 문자

를 표현할 수 있다.

- 7비트 또는 8비트 사용
- 총 128개(또는 256개) 문자 표현 가능

---

### 3.2 ASCII 예시

'A' → 65

'a' → 97

'0' → 48

즉, 문자 `'A'`는 내부적으로 숫자 `65`로 저장된다.

---

### 3.3 ASCII의 한계

ASCII는 다음 문자를 표현할 수 없다.

- 한글
- 중국어
- 일본어
- 이모지

이로 인해 더 많은 문자를 표현할 수 있는 인코딩 방식이 필요해졌다.

---

## 4. Unicode

### 4.1 Unicode란?

Unicode는

**전 세계 모든 문자에 고유한 번호를 부여**하는 문자 체계이다.

- 문자 하나당 고유한 코드 포인트 부여
- 언어와 상관없이 문자 표현 가능

예를 들어,

'A' → U+0041

'가' → U+AC00

Unicode는 "이 문자가 어떤 문자다"를 정의할 뿐, **어떻게 저장할지는 정하지 않는다.**

---

## 5. UTF-8 인코딩

### 5.1 UTF-8이란?

UTF-8은

Unicode 문자를 실제로 **0과 1로 저장하는 방식**이다.

- 가변 길이 인코딩
- 1바이트 ~ 4바이트 사용
- ASCII와 완벽히 호환됨

---

### 5.2 UTF-8 저장 방식 예시

'A' → 1바이트

'가' → 3바이트

'😀' → 4바이트

즉,

- 자주 사용하는 문자는 짧게
- 덜 사용하는 문자는 길게

저장하여 공간을 효율적으로 사용한다.

---

## 6. 문자 깨짐이 발생하는 이유

문자 깨짐은 **인코딩 방식이 서로 다를 때** 발생한다.

예를 들어,

- 저장: UTF-8
- 해석: EUC-KR

과 같이 인코딩 방식이 다르면 문자가 올바르게 표시되지 않는다.

> 문자가 깨진다는 것은
> 
> 
> **문자가 잘못 저장된 것이 아니라 잘못 해석된 것**이다.
> 

---

## 7. 정리

- 컴퓨터는 문자를 직접 이해하지 못한다
- 문자는 숫자로 변환되어 저장된다
- 문자 → 숫자로 바꾸는 규칙을 문자 인코딩이라 한다
- ASCII는 기본적인 문자 인코딩 방식이다
- Unicode는 모든 문자에 번호를 부여하는 체계이다
- UTF-8은 Unicode를 0과 1로 저장하는 대표적인 방식이다